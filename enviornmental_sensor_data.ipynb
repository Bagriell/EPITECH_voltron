{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "enviornmental-sensor-data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Voltron - AI\n",
        "\n",
        "We had the task to help monitoring vineyards with data that should comes from multiple sensors on the spot.\n",
        "We will try to do forecasting on temperature first in order to be aware of future trends.   \n",
        "\n",
        "Firstly we analyse and format our data in order to have a glimpse at its structure and distribution.  \n",
        "Then we will use [prophet](https://facebook.github.io/prophet/) in order to predict futur value for time serie.\n",
        "\n",
        "\n",
        "**Usage**:  \n",
        "You need to Upload your [kaggle key](https://www.kaggle.com/docs/api) or upload csv on session.  \n",
        "1. Download dataset \n",
        "2. Cleaning dataset\n",
        "3. Plots\n",
        "4. Create model\n",
        "5. Prediction\n",
        "6. Testing model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Em2ivBzVHGJ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Download dataset\n",
        "\n",
        "First we upload our kaggle key to the environment.\n",
        "Then we download it and install pophet - our tool to build our model.  \n",
        "Finally we read our data and look at its structure from our DataFrame variable."
      ],
      "metadata": {
        "id": "GaghURhD57br"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!mv ./kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets list"
      ],
      "metadata": {
        "id": "rT_3IxPX37MD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPb41iai1EBs"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d garystafford/environmental-sensor-data-132k\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip environmental-sensor-data-132k.zip"
      ],
      "metadata": {
        "id": "vSUVtgQV1GrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install prophet\n",
        "# see https://facebook.github.io/prophet/ for further details"
      ],
      "metadata": {
        "id": "Ihg0HJ3gQEqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px \n",
        "from prophet import Prophet\n",
        "from prophet.diagnostics import cross_validation\n",
        "\n",
        "\n",
        "import seaborn as sn\n"
      ],
      "metadata": {
        "id": "k9KciZHS4UML"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('iot_telemetry_data.csv')\n",
        "\n",
        "\n",
        "print(f\"\"\"\n",
        "##############################\n",
        "Shape:\n",
        "  {df.shape}\n",
        "\n",
        "Dtypes:\n",
        "  {df.dtypes}\n",
        "############################## \n",
        "\"\"\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "U--4aQ8R4QP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## cleaning data\n",
        "\n",
        "In order to use our data properly we convert our time column to datetime.  \n",
        "Then we group our data by devices."
      ],
      "metadata": {
        "id": "BatIJStK5tct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)\n",
        "start = datetime(1970, 1, 1)  # Unix epoch start time\n",
        "df['time'] =  df['ts'].apply(lambda x: start + timedelta(seconds=x))\n",
        "df.replace(['b8:27:eb:bf:9d:51', '00:0f:00:70:91:0a', '1c:bf:ce:15:ec:4d'], ['Device1','Device2','Device3'], inplace=True)\n",
        "df"
      ],
      "metadata": {
        "id": "QD9Bc9TEDb8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['time'].min())\n",
        "print(df['time'].max())\n"
      ],
      "metadata": {
        "id": "V2b2vsqnY-Se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_1 = df[df.device == 'Device1']\n",
        "data_2 = df[df.device == 'Device2']\n",
        "data_3 = df[df.device == 'Device3']\n",
        "\n",
        "print(f\"\"\"\n",
        "  data_1.shape: {data_1.shape}\n",
        "  data_2.shape: {data_2.shape}\n",
        "  data_3.shape: {data_3.shape}\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "VBMi_3QaoIMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Plots\n",
        "\n",
        "We plot our data by device and notice that each of it gathered very different values.  \n",
        "We notice especilally by plotting by average that our 3 device are situated in very differents environments."
      ],
      "metadata": {
        "id": "k_cIhrluXDq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 6), dpi=80)\n",
        "\n",
        "plt.plot(data_1['time'], data_1['co'], label='Device1')\n",
        "plt.plot(data_2['time'], data_2['co'], label='Device2')\n",
        "plt.plot(data_3['time'], data_3['co'], label='Device3')\n",
        "\n",
        "plt.title('carbon m')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bzIEE2Bcxvtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 6), dpi=80)\n",
        "\n",
        "plt.plot(data_1['time'], data_1['humidity'], label='Device1')\n",
        "plt.plot(data_2['time'], data_2['humidity'], label='Device2')\n",
        "plt.plot(data_3['time'], data_3['humidity'], label='Device3')\n",
        "\n",
        "plt.title('humidity')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bAr1ZD-LxwW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 6), dpi=80)\n",
        "\n",
        "plt.plot(data_1['time'], data_1['temp'], label='Device1')\n",
        "plt.plot(data_2['time'], data_2['temp'], label='Device_C2')\n",
        "plt.plot(data_3['time'], data_3['temp'], label='Device_C3')\n",
        "\n",
        "plt.title('temperature')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uWddyrXT_9yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We plot temperature by day in order to have wider vision of the temperature"
      ],
      "metadata": {
        "id": "tWGPBE3zL0sg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grp_1 = data_1.groupby(data_1[\"time\"].dt.day).mean()\n",
        "grp_1['ts'] = grp_1['ts'].apply(lambda x: start + timedelta(seconds=x))\n",
        "\n",
        "grp_2 = data_2.groupby(data_2[\"time\"].dt.day).mean()\n",
        "grp_2['ts'] = grp_2['ts'].apply(lambda x: start + timedelta(seconds=x))\n",
        "\n",
        "grp_3 = data_3.groupby(data_3[\"time\"].dt.day).mean()\n",
        "grp_3['ts'] = grp_3['ts'].apply(lambda x: start + timedelta(seconds=x))\n",
        "plt.figure(figsize=(20, 6), dpi=80)\n",
        "\n",
        "\n",
        "plt.plot(grp_1['ts'], grp_1['temp'], label='Device1')\n",
        "plt.plot(grp_2['ts'], grp_2['temp'], label='Device2')\n",
        "plt.plot(grp_3['ts'], grp_3['temp'], label='Device3')\n",
        "plt.title('temperature per day average')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tYeG3DvDEYZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_prophet_1 = pd.DataFrame({\"ds\": data_1[\"time\"], 'y': data_1['temp']})\n",
        "df_prophet_1"
      ],
      "metadata": {
        "id": "J74MUztTiFsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create model"
      ],
      "metadata": {
        "id": "GRfjvhQEXZMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from prophet import Prophet\n",
        "from prophet.plot import plot_yearly\n",
        "from prophet.diagnostics import cross_validation\n",
        "\n",
        "\n",
        "\n",
        "model = Prophet()\n",
        "model.fit(df_prophet_1)"
      ],
      "metadata": {
        "id": "kl8Vi-Fvhwdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "4GiO4JCpXkq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "future = model.make_future_dataframe(periods=15000, freq=\"4S\")  \n",
        "forecast = model.predict(future)\n",
        "fig1 = model.plot(forecast)"
      ],
      "metadata": {
        "id": "X7GmvGntjJS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig2 = model.plot_components(forecast)\n"
      ],
      "metadata": {
        "id": "bSC-qwH4u_qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forecast"
      ],
      "metadata": {
        "id": "C_wYOhb3gzgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## testing model\n",
        "\n",
        "Cross validation do a cut in the timevalues and then compute differents metrics (mae, map,...) tryng to predict the cut part of data."
      ],
      "metadata": {
        "id": "UsekD9irdJd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_cv = cross_validation(model, initial='5 days', period='1day', horizon = '2days')"
      ],
      "metadata": {
        "id": "aq1aooVvXMbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cv"
      ],
      "metadata": {
        "id": "u4US8dOFZ_F-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from prophet.plot import plot_cross_validation_metric\n",
        "from prophet.diagnostics import performance_metrics\n",
        "\n",
        "\n",
        "fig = plot_cross_validation_metric(df_cv, metric='mape')\n"
      ],
      "metadata": {
        "id": "ntSjdVjrb9sE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_p = performance_metrics(df_cv)\n",
        "df_p.head()"
      ],
      "metadata": {
        "id": "txMustTacK6b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}